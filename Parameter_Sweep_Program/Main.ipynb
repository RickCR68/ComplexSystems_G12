{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# F1 Aerodynamics: Complete Complexity & Chaos Analysis\n",
    "\n",
    "This notebook performs comprehensive flow analysis including:\n",
    "- **Velocity & Pressure fields**\n",
    "- **Vorticity and flow structures**\n",
    "- **Energy spectra** (Kolmogorov cascade)\n",
    "- **Chaos detection** (Lyapunov exponents, bifurcations)\n",
    "- **Phase space reconstruction**\n",
    "- **Dynamical regime classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "from lbm_core import LBMSolver\n",
    "from boundaries import TunnelBoundaries\n",
    "from analysis import plot_complexity_dashboard\n",
    "from aerodynamics import calculate_lift_drag, check_ground_effect\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from scipy import signal, stats\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.optimize import curve_fit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config_markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "NX, NY = 400, 100\n",
    "GROUND_TYPE = \"no_slip\"\n",
    "SIMULATION_STEPS = 8000  # Needs to be longer for chaos analysis\n",
    "CHECKPOINT_INTERVAL = 100\n",
    "SPECTRUM_INTERVAL = 500\n",
    "\n",
    "# PARAMETER SWEEP\n",
    "# Option 1: Bifurcation analysis (vary one parameter densely)\n",
    "USE_BIFURCATION_MODE = True\n",
    "\n",
    "if USE_BIFURCATION_MODE:\n",
    "    # Choose which parameter to sweep for bifurcation analysis\n",
    "    BIFURCATION_PARAMETER = 'ride_height'  # Options: 'reynolds' or 'ride_height'\n",
    "    \n",
    "    if BIFURCATION_PARAMETER == 'reynolds':\n",
    "        # Sweep Reynolds number, fix ride height\n",
    "        RIDE_HEIGHTS = [19]  # Fixed ride height\n",
    "        REYNOLDS_NUMBERS = np.linspace(1000, 25000, 25)  # Dense Reynolds sweep\n",
    "    \n",
    "    elif BIFURCATION_PARAMETER == 'ride_height':\n",
    "        # Sweep ride height, fix Reynolds number\n",
    "        RIDE_HEIGHTS = np.linspace(8, 40, 25)  # Dense ride height sweep\n",
    "        REYNOLDS_NUMBERS = [500]  # Fixed Reynolds number\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"BIFURCATION_PARAMETER must be 'reynolds' or 'ride_height'\")\n",
    "\n",
    "else:\n",
    "    # Option 2: Multi-parameter exploration\n",
    "    RIDE_HEIGHTS = [10, 19, 35]\n",
    "    REYNOLDS_NUMBERS = [1000, 5000, 10000, 20000]\n",
    "    BIFURCATION_PARAMETER = None\n",
    "\n",
    "# Output\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_dir = Path(f\"complete_analysis_{timestamp}\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "(results_dir / \"snapshots\").mkdir(exist_ok=True)\n",
    "(results_dir / \"pressure\").mkdir(exist_ok=True)\n",
    "(results_dir / \"spectra\").mkdir(exist_ok=True)\n",
    "(results_dir / \"chaos\").mkdir(exist_ok=True)\n",
    "(results_dir / \"timeseries\").mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Results = {results_dir}\")\n",
    "print(f\"Total simulations: {len(RIDE_HEIGHTS) * len(REYNOLDS_NUMBERS)}\")\n",
    "print(f\"Mode: {'Bifurcation Analysis' if USE_BIFURCATION_MODE else 'Multi-Parameter Exploration'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools",
   "metadata": {},
   "source": [
    "## Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzer_class",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteFlowAnalyzer:\n",
    "    \"\"\"Unified analyzer: phenomena + spectra + chaos\"\"\"\n",
    "    \n",
    "    def __init__(self, ride_height, reynolds, nx, ny):\n",
    "        self.ride_height = ride_height\n",
    "        self.reynolds = reynolds\n",
    "        self.nx = nx\n",
    "        self.ny = ny\n",
    "        \n",
    "        # Flow field storage\n",
    "        self.velocity_snapshots = []\n",
    "        self.vorticity_snapshots = []\n",
    "        self.pressure_snapshots = []\n",
    "        self.snapshot_steps = []\n",
    "        \n",
    "        # Time series\n",
    "        self.lift_history = []\n",
    "        self.drag_history = []\n",
    "        self.step_history = []\n",
    "        self.max_velocity_history = []\n",
    "        self.vorticity_magnitude = []\n",
    "        \n",
    "        # Spectral data\n",
    "        self.energy_spectra_1d = []\n",
    "        self.energy_spectra_2d = []\n",
    "        self.spectrum_steps = []\n",
    "        \n",
    "        # Chaos metrics\n",
    "        self.lyapunov_exponent = None\n",
    "        self.correlation_dimension = None\n",
    "        self.chaos_test_result = None\n",
    "        self.attractor_type = None\n",
    "        self.embedding_dim = None\n",
    "        self.embedding_delay = None\n",
    "        \n",
    "        # Phenomena flags\n",
    "        self.vortex_shedding = False\n",
    "        self.shedding_frequency = None\n",
    "        self.turbulence_intensity = None\n",
    "        self.kolmogorov_slope = None\n",
    "    \n",
    "    # Field calculations\n",
    "    \n",
    "    def calculate_pressure_field(self, solver, mask):\n",
    "        \"\"\"Pressure from LBM density\"\"\"\n",
    "        rho = np.sum(solver.f, axis=2)\n",
    "        pressure = (rho - 1.0) / (0.5 * 1.0 * solver.u_inlet**2)\n",
    "        pressure[mask] = np.nan\n",
    "        return pressure\n",
    "    \n",
    "    def calculate_vorticity(self, velocity_field, mask):\n",
    "        \"\"\"Vorticity\"\"\"\n",
    "        u = velocity_field[:,:,0]\n",
    "        v = velocity_field[:,:,1]\n",
    "        du_dy = np.gradient(u, axis=0)\n",
    "        dv_dx = np.gradient(v, axis=1)\n",
    "        vorticity = dv_dx - du_dy\n",
    "        vorticity[mask] = np.nan\n",
    "        return vorticity\n",
    "    \n",
    "    # Spectral Analysis\n",
    "    \n",
    "    def compute_energy_spectrum(self, velocity_field, mask):\n",
    "        \"\"\"Turbulent kinetic energy spectrum E(k)\"\"\"\n",
    "        u = velocity_field[:,:,0].copy()\n",
    "        v = velocity_field[:,:,1].copy()\n",
    "        u[mask] = 0\n",
    "        v[mask] = 0\n",
    "        \n",
    "        u_fft = np.fft.fft2(u)\n",
    "        v_fft = np.fft.fft2(v)\n",
    "        energy_2d = 0.5 * (np.abs(u_fft)**2 + np.abs(v_fft)**2)\n",
    "        \n",
    "        kx = np.fft.fftfreq(self.nx) * self.nx\n",
    "        ky = np.fft.fftfreq(self.ny) * self.ny\n",
    "        kx_grid, ky_grid = np.meshgrid(kx, ky)\n",
    "        k_mag = np.sqrt(kx_grid**2 + ky_grid**2)\n",
    "        \n",
    "        energy_2d_shifted = np.fft.fftshift(energy_2d)\n",
    "        \n",
    "        # Radial average\n",
    "        k_bins = np.arange(0.5, min(self.nx, self.ny)//2, 1.0)\n",
    "        k_centers = 0.5 * (k_bins[:-1] + k_bins[1:])\n",
    "        energy_1d = np.zeros(len(k_centers))\n",
    "        \n",
    "        for i, k_center in enumerate(k_centers):\n",
    "            mask_ring = (k_mag >= k_bins[i]) & (k_mag < k_bins[i+1])\n",
    "            if np.any(mask_ring):\n",
    "                energy_1d[i] = np.mean(energy_2d[mask_ring])\n",
    "        \n",
    "        return k_centers, energy_1d, energy_2d_shifted\n",
    "    \n",
    "    def fit_kolmogorov_slope(self, k, E_k):\n",
    "        \"\"\"Fit power law to inertial range\"\"\"\n",
    "        valid = (E_k > 0) & (k > 1)\n",
    "        if np.sum(valid) < 5:\n",
    "            return None\n",
    "        \n",
    "        k_valid = k[valid]\n",
    "        E_valid = E_k[valid]\n",
    "        log_k = np.log10(k_valid)\n",
    "        log_E = np.log10(E_valid)\n",
    "        \n",
    "        mid_start = len(log_k) // 4\n",
    "        mid_end = 3 * len(log_k) // 4\n",
    "        if mid_end <= mid_start + 2:\n",
    "            return None\n",
    "        \n",
    "        coeffs = np.polyfit(log_k[mid_start:mid_end], log_E[mid_start:mid_end], 1)\n",
    "        return coeffs[0]\n",
    "    \n",
    "    # Chaos Analysis\n",
    "    \n",
    "    def find_embedding_parameters(self, signal_data):\n",
    "        \"\"\"Find optimal embedding via AMI\"\"\"\n",
    "        max_delay = min(100, len(signal_data) // 10)\n",
    "        delays = np.arange(1, max_delay)\n",
    "        ami = np.zeros(len(delays))\n",
    "        \n",
    "        for i, delay in enumerate(delays):\n",
    "            ami[i] = self._mutual_information(signal_data[:-delay], signal_data[delay:])\n",
    "        \n",
    "        ami_mins = signal.argrelextrema(ami, np.less)[0]\n",
    "        if len(ami_mins) > 0:\n",
    "            return 3, delays[ami_mins[0]]\n",
    "        return 3, delays[np.argmin(ami)] if len(ami) > 0 else 10\n",
    "    \n",
    "    def _mutual_information(self, x, y, bins=20):\n",
    "        \"\"\"Compute MI between signals\"\"\"\n",
    "        hist_xy, _, _ = np.histogram2d(x, y, bins=bins)\n",
    "        hist_x, _ = np.histogram(x, bins=bins)\n",
    "        hist_y, _ = np.histogram(y, bins=bins)\n",
    "        \n",
    "        p_xy = hist_xy / np.sum(hist_xy)\n",
    "        p_x = hist_x / np.sum(hist_x)\n",
    "        p_y = hist_y / np.sum(hist_y)\n",
    "        \n",
    "        mi = 0\n",
    "        for i in range(bins):\n",
    "            for j in range(bins):\n",
    "                if p_xy[i,j] > 0:\n",
    "                    mi += p_xy[i,j] * np.log(p_xy[i,j] / (p_x[i] * p_y[j] + 1e-10))\n",
    "        return mi\n",
    "    \n",
    "    def reconstruct_phase_space(self, signal_data, dim, delay):\n",
    "        \"\"\"Time-delay embedding\"\"\"\n",
    "        n_vectors = len(signal_data) - (dim - 1) * delay\n",
    "        embedded = np.zeros((n_vectors, dim))\n",
    "        for i in range(dim):\n",
    "            embedded[:, i] = signal_data[i*delay : i*delay + n_vectors]\n",
    "        return embedded\n",
    "    \n",
    "    def largest_lyapunov_exponent(self, signal_data, dt=1.0):\n",
    "        \"\"\"Estimate largest Lyapunov exponent\"\"\"\n",
    "        dim, delay = self.find_embedding_parameters(signal_data)\n",
    "        embedded = self.reconstruct_phase_space(signal_data, dim, delay)\n",
    "        \n",
    "        n_points = len(embedded)\n",
    "        max_iter = min(100, n_points // 10)\n",
    "        \n",
    "        distances = squareform(pdist(embedded))\n",
    "        np.fill_diagonal(distances, np.inf)\n",
    "        \n",
    "        divergence = []\n",
    "        for i in range(max_iter):\n",
    "            valid_indices = np.where(np.arange(n_points) + i < n_points)[0]\n",
    "            if len(valid_indices) < n_points // 2:\n",
    "                break\n",
    "            \n",
    "            nn_idx = np.argmin(distances[valid_indices], axis=1)\n",
    "            separations = []\n",
    "            for j, idx in enumerate(valid_indices):\n",
    "                if idx + i < n_points and nn_idx[j] + i < n_points:\n",
    "                    sep = np.linalg.norm(embedded[idx + i] - embedded[nn_idx[j] + i])\n",
    "                    if sep > 0:\n",
    "                        separations.append(np.log(sep))\n",
    "            \n",
    "            if len(separations) > 0:\n",
    "                divergence.append(np.mean(separations))\n",
    "        \n",
    "        if len(divergence) > 10:\n",
    "            x = np.arange(len(divergence)) * dt\n",
    "            coeffs = np.polyfit(x[:len(divergence)//2], divergence[:len(divergence)//2], 1)\n",
    "            return coeffs[0], dim, delay\n",
    "        return None, dim, delay\n",
    "    \n",
    "    def zero_one_test(self, signal_data):\n",
    "        \"\"\"0-1 test for chaos\"\"\"\n",
    "        n = len(signal_data)\n",
    "        c = np.pi / 5\n",
    "        phi = np.cumsum(signal_data * np.cos(c * np.arange(n)))\n",
    "        \n",
    "        M = np.zeros(n // 10)\n",
    "        for j in range(1, len(M)):\n",
    "            M[j] = np.mean((phi[j:] - phi[:-j])**2)\n",
    "        \n",
    "        n_fit = np.arange(len(M))\n",
    "        valid = M > 0\n",
    "        if np.sum(valid) > 5:\n",
    "            K = np.polyfit(n_fit[valid], M[valid], 1)[0]\n",
    "            return K\n",
    "        return None\n",
    "    \n",
    "    def classify_attractor(self):\n",
    "        \"\"\"Classify attractor type\"\"\"\n",
    "        if self.lyapunov_exponent is not None and self.lyapunov_exponent > 0.01:\n",
    "            return \"Strange Attractor (Chaotic)\"\n",
    "        elif self.lyapunov_exponent is not None and abs(self.lyapunov_exponent) < 0.001:\n",
    "            freqs, psd = signal.periodogram(self.lift_history, fs=1.0)\n",
    "            peaks, _ = signal.find_peaks(psd, height=np.max(psd)*0.1)\n",
    "            \n",
    "            if len(peaks) == 1:\n",
    "                return \"Limit Cycle (Periodic)\"\n",
    "            elif len(peaks) > 1:\n",
    "                return \"Torus (Quasi-periodic)\"\n",
    "            else:\n",
    "                return \"Fixed Point (Steady)\"\n",
    "        return \"Transitional\"\n",
    "    \n",
    "    # Data Collection\n",
    "    \n",
    "    def add_snapshot(self, step, solver, bounds_mask):\n",
    "        \"\"\"Capture full flow state\"\"\"\n",
    "        self.snapshot_steps.append(step)\n",
    "        \n",
    "        # Velocity\n",
    "        v_mag = np.sqrt(solver.u[:,:,0]**2 + solver.u[:,:,1]**2)\n",
    "        v_mag[bounds_mask] = np.nan\n",
    "        self.velocity_snapshots.append(v_mag.copy())\n",
    "        \n",
    "        # Vorticity\n",
    "        vorticity = self.calculate_vorticity(solver.u, bounds_mask)\n",
    "        self.vorticity_snapshots.append(vorticity)\n",
    "        self.vorticity_magnitude.append(np.nansum(np.abs(vorticity)))\n",
    "        \n",
    "        # Pressure\n",
    "        pressure = self.calculate_pressure_field(solver, bounds_mask)\n",
    "        self.pressure_snapshots.append(pressure)\n",
    "    \n",
    "    def add_spectrum(self, step, solver, bounds_mask):\n",
    "        \"\"\"Compute energy spectrum\"\"\"\n",
    "        k, E_k, E_2d = self.compute_energy_spectrum(solver.u, bounds_mask)\n",
    "        self.spectrum_steps.append(step)\n",
    "        self.energy_spectra_1d.append((k, E_k))\n",
    "        self.energy_spectra_2d.append(E_2d)\n",
    "    \n",
    "    def add_step_data(self, step, lift, drag, max_vel):\n",
    "        \"\"\"Record time series\"\"\"\n",
    "        self.step_history.append(step)\n",
    "        self.lift_history.append(lift)\n",
    "        self.drag_history.append(drag)\n",
    "        self.max_velocity_history.append(max_vel)\n",
    "    \n",
    "    # Analysis\n",
    "    \n",
    "    def analyze_all(self):\n",
    "        \"\"\"Run complete analysis pipeline\"\"\"\n",
    "        print(f\"  Analyzing Re={self.reynolds}, RH={self.ride_height}...\")\n",
    "        \n",
    "        # Use second half for steady-state\n",
    "        steady_start = len(self.lift_history) // 2\n",
    "        lift_steady = np.array(self.lift_history[steady_start:])\n",
    "        \n",
    "        # Vortex shedding\n",
    "        if len(lift_steady) > 500:\n",
    "            lift_signal = lift_steady - np.mean(lift_steady)\n",
    "            fft = np.fft.fft(lift_signal)\n",
    "            freqs = np.fft.fftfreq(len(lift_signal))\n",
    "            power = np.abs(fft)**2\n",
    "            \n",
    "            positive_freqs = freqs[1:len(freqs)//2]\n",
    "            positive_power = power[1:len(power)//2]\n",
    "            \n",
    "            if len(positive_power) > 0:\n",
    "                peak_idx = np.argmax(positive_power)\n",
    "                if positive_power[peak_idx] > 5 * np.mean(positive_power):\n",
    "                    self.vortex_shedding = True\n",
    "                    self.shedding_frequency = abs(positive_freqs[peak_idx])\n",
    "        \n",
    "        # Turbulence intensity\n",
    "        if len(self.max_velocity_history) > 100:\n",
    "            vel_array = np.array(self.max_velocity_history[-500:])\n",
    "            mean_vel = np.mean(vel_array)\n",
    "            if mean_vel > 0:\n",
    "                self.turbulence_intensity = np.std(vel_array) / mean_vel\n",
    "        \n",
    "        # Energy cascade\n",
    "        if len(self.energy_spectra_1d) > 0:\n",
    "            k, E_k = self.energy_spectra_1d[-1]\n",
    "            self.kolmogorov_slope = self.fit_kolmogorov_slope(k, E_k)\n",
    "        \n",
    "        # Chaos metrics\n",
    "        if len(lift_steady) > 200:\n",
    "            lyap, dim, delay = self.largest_lyapunov_exponent(lift_steady, dt=1.0)\n",
    "            self.lyapunov_exponent = lyap\n",
    "            self.embedding_dim = dim\n",
    "            self.embedding_delay = delay\n",
    "            self.chaos_test_result = self.zero_one_test(lift_steady)\n",
    "            self.attractor_type = self.classify_attractor()\n",
    "        \n",
    "        print(f\"    Lyapunov: {self.lyapunov_exponent:.6f}\" if self.lyapunov_exponent else \"    Lyapunov: N/A\")\n",
    "        print(f\"    Attractor: {self.attractor_type}\")\n",
    "        print(f\"    Vortex shedding: {'YES' if self.vortex_shedding else 'NO'}\")\n",
    "        if self.kolmogorov_slope:\n",
    "            print(f\"    Energy cascade slope: {self.kolmogorov_slope:.3f}\")\n",
    "    \n",
    "    def save(self, base_dir):\n",
    "        \"\"\"Save all data\"\"\"\n",
    "        base_dir = Path(base_dir)\n",
    "        prefix = f\"rh{self.ride_height:.0f}_re{self.reynolds:.0f}\"\n",
    "        \n",
    "        # Summary\n",
    "        summary = {\n",
    "            'ride_height': float(self.ride_height),\n",
    "            'reynolds': float(self.reynolds),\n",
    "            'lyapunov': float(self.lyapunov_exponent) if self.lyapunov_exponent else None,\n",
    "            'attractor_type': self.attractor_type,\n",
    "            'vortex_shedding': self.vortex_shedding,\n",
    "            'shedding_frequency': float(self.shedding_frequency) if self.shedding_frequency else None,\n",
    "            'turbulence_intensity': float(self.turbulence_intensity) if self.turbulence_intensity else None,\n",
    "            'kolmogorov_slope': float(self.kolmogorov_slope) if self.kolmogorov_slope else None,\n",
    "        }\n",
    "        \n",
    "        with open(base_dir / \"chaos\" / f\"{prefix}_summary.json\", 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        # Time series\n",
    "        np.savez_compressed(\n",
    "            base_dir / \"timeseries\" / f\"{prefix}_timeseries.npz\",\n",
    "            steps=self.step_history,\n",
    "            lift=self.lift_history,\n",
    "            drag=self.drag_history\n",
    "        )\n",
    "        \n",
    "        # Snapshots\n",
    "        np.savez_compressed(\n",
    "            base_dir / \"snapshots\" / f\"{prefix}_snapshots.npz\",\n",
    "            velocity=np.array(self.velocity_snapshots),\n",
    "            vorticity=np.array(self.vorticity_snapshots),\n",
    "            pressure=np.array(self.pressure_snapshots),\n",
    "            steps=self.snapshot_steps\n",
    "        )\n",
    "        \n",
    "        # Spectra\n",
    "        if len(self.energy_spectra_1d) > 0:\n",
    "            np.savez_compressed(\n",
    "                base_dir / \"spectra\" / f\"{prefix}_spectra.npz\",\n",
    "                k_values=[k for k, _ in self.energy_spectra_1d],\n",
    "                E_k_values=[E for _, E in self.energy_spectra_1d]\n",
    "            )\n",
    "\n",
    "# Approximate F1 Shape Mask\n",
    "\n",
    "def create_geometry(bounds, ride_height):\n",
    "    \"\"\"Create F1 car geometry\"\"\"\n",
    "    bounds.add_ground(type=GROUND_TYPE)\n",
    "    bounds.add_f1_wing_proxy(x_pos=150, height=ride_height, length=60, slope=0.45)\n",
    "    bounds.add_rectangular_obstacle(x_start=210, y_start=ride_height + 1, length=120, height=20)\n",
    "    bounds.add_reverse_triangle(x_pos=240, height=ride_height + 20, length=90, slope=2/9)\n",
    "    bounds.add_f1_wing_proxy(x_pos=300, height=ride_height + 30, length=30, slope=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run",
   "metadata": {},
   "source": [
    "## Run Complete Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_sweep",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analyzers = []\n",
    "\n",
    "total_sims = len(RIDE_HEIGHTS) * len(REYNOLDS_NUMBERS)\n",
    "sim_counter = 0\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPLETE FLOW ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for reynolds in REYNOLDS_NUMBERS:\n",
    "    for ride_height in RIDE_HEIGHTS:\n",
    "        sim_counter += 1\n",
    "        print(f\"\\n[{sim_counter}/{total_sims}] Re={reynolds:.0f}, RH={ride_height:.1f}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        analyzer = CompleteFlowAnalyzer(ride_height, reynolds, NX, NY)\n",
    "        \n",
    "        solver = LBMSolver(NX, NY, int(reynolds), u_inlet=0.1)\n",
    "        bounds = TunnelBoundaries(NX, NY)\n",
    "        create_geometry(bounds, ride_height)\n",
    "        \n",
    "        relevant_x_start = 145\n",
    "        relevant_x_end = 335\n",
    "        relevant_y_start = 5\n",
    "        relevant_y_end = min(75, int(ride_height) + 60)\n",
    "        \n",
    "        print(f\"  Running {SIMULATION_STEPS} steps...\")\n",
    "        for step in range(SIMULATION_STEPS):\n",
    "            solver.collide_and_stream(bounds.mask)\n",
    "            bounds.apply_inlet_outlet(solver)\n",
    "            \n",
    "            # Sample frequently for chaos analysis\n",
    "            if step % 5 == 0:\n",
    "                fx, fy = calculate_lift_drag(\n",
    "                    solver, bounds,\n",
    "                    x_start=relevant_x_start, x_end=relevant_x_end,\n",
    "                    y_start=relevant_y_start, y_end=relevant_y_end\n",
    "                )\n",
    "                max_vel = np.max(np.sqrt(solver.u[:,:,0]**2 + solver.u[:,:,1]**2))\n",
    "                analyzer.add_step_data(step, fy, fx, max_vel)\n",
    "            \n",
    "            # Snapshots\n",
    "            if step % CHECKPOINT_INTERVAL == 0 or step == SIMULATION_STEPS - 1:\n",
    "                analyzer.add_snapshot(step, solver, bounds.mask)\n",
    "            \n",
    "            # Spectra\n",
    "            if step % SPECTRUM_INTERVAL == 0 and step > 0:\n",
    "                analyzer.add_spectrum(step, solver, bounds.mask)\n",
    "        \n",
    "        # Final spectrum\n",
    "        analyzer.add_spectrum(SIMULATION_STEPS, solver, bounds.mask)\n",
    "        \n",
    "        # Analyze everything\n",
    "        analyzer.analyze_all()\n",
    "        analyzer.save(results_dir)\n",
    "        all_analyzers.append(analyzer)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz_bifurcation",
   "metadata": {},
   "source": [
    "## Bifurcation Diagram (if in bifurcation mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_bifurcation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_BIFURCATION_MODE:\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "    \n",
    "    # Determine which parameter is being varied\n",
    "    if BIFURCATION_PARAMETER == 'reynolds':\n",
    "        params = np.array([a.reynolds for a in all_analyzers])\n",
    "        param_label = 'Reynolds Number'\n",
    "    else:  # ride_height\n",
    "        params = np.array([a.ride_height for a in all_analyzers])\n",
    "        param_label = 'Ride Height (grid units)'\n",
    "    \n",
    "    # Bifurcation diagram\n",
    "    ax = axes[0]\n",
    "    for analyzer in all_analyzers:\n",
    "        steady_start = len(analyzer.lift_history) // 2\n",
    "        lift_steady = np.array(analyzer.lift_history[steady_start:])\n",
    "        peaks, _ = signal.find_peaks(lift_steady, distance=10)\n",
    "        valleys, _ = signal.find_peaks(-lift_steady, distance=10)\n",
    "        extrema = np.concatenate([lift_steady[peaks], lift_steady[valleys]])\n",
    "        \n",
    "        if len(extrema) > 0:\n",
    "            param_val = analyzer.reynolds if BIFURCATION_PARAMETER == 'reynolds' else analyzer.ride_height\n",
    "            ax.plot([param_val]*len(extrema), extrema, 'b.', markersize=2, alpha=0.6)\n",
    "    \n",
    "    ax.set_xlabel(param_label, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Lift Force (Extrema)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Bifurcation Diagram', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Lyapunov exponent\n",
    "    ax = axes[1]\n",
    "    lyapunovs = [a.lyapunov_exponent if a.lyapunov_exponent else 0 for a in all_analyzers]\n",
    "    ax.plot(params, lyapunovs, 'ro-', linewidth=2, markersize=6)\n",
    "    ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    ax.fill_between(params, 0, lyapunovs, where=np.array(lyapunovs)>0, alpha=0.3, color='red', label='Chaotic (λ>0)')\n",
    "    ax.set_xlabel(param_label, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Lyapunov Exponent', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Chaos Indicator', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Attractor types\n",
    "    ax = axes[2]\n",
    "    attractor_types = [a.attractor_type for a in all_analyzers]\n",
    "    unique_types = list(set(attractor_types))\n",
    "    type_to_num = {t: i for i, t in enumerate(unique_types)}\n",
    "    type_nums = [type_to_num[t] for t in attractor_types]\n",
    "    \n",
    "    ax.plot(params, type_nums, 'go-', linewidth=2, markersize=8)\n",
    "    ax.set_yticks(range(len(unique_types)))\n",
    "    ax.set_yticklabels(unique_types, fontsize=9)\n",
    "    ax.set_xlabel(param_label, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Attractor Type', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Dynamical Regime Transitions', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Mark bifurcations\n",
    "    for i in range(1, len(attractor_types)):\n",
    "        if attractor_types[i] != attractor_types[i-1]:\n",
    "            ax.axvline(x=params[i], color='red', linestyle=':', alpha=0.5, linewidth=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / \"chaos\" / \"bifurcation_diagram.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"\\nBifurcation diagram saved (parameter: {BIFURCATION_PARAMETER})\")\n",
    "else:\n",
    "    print(\"\\n Skipping bifurcation diagram (not in bifurcation mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz_spectra",
   "metadata": {},
   "source": [
    "## Energy Spectra Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_spectra",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating energy spectrum visualizations...\\n\")\n",
    "\n",
    "for analyzer in all_analyzers:\n",
    "    if len(analyzer.energy_spectra_1d) == 0:\n",
    "        continue\n",
    "    \n",
    "    k, E_k = analyzer.energy_spectra_1d[-1]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    valid = (E_k > 0) & (k > 0.5)\n",
    "    ax.loglog(k[valid], E_k[valid], 'b-', linewidth=2.5, label='Simulation')\n",
    "    \n",
    "    # Theoretical slopes\n",
    "    k_theory = k[valid]\n",
    "    if len(k_theory) > 0:\n",
    "        C_kolm = E_k[valid][len(k_theory)//3] * (k_theory[len(k_theory)//3] ** (5/3))\n",
    "        E_kolm = C_kolm * k_theory ** (-5/3)\n",
    "        ax.loglog(k_theory, E_kolm, 'g--', linewidth=2, alpha=0.7, label='Kolmogorov $k^{-5/3}$')\n",
    "        \n",
    "        C_kraich = E_k[valid][len(k_theory)//3] * (k_theory[len(k_theory)//3] ** 3)\n",
    "        E_kraich = C_kraich * k_theory ** (-3)\n",
    "        ax.loglog(k_theory, E_kraich, 'r:', linewidth=2, alpha=0.7, label='Kraichnan $k^{-3}$')\n",
    "    \n",
    "    ax.set_xlabel('Wave Number $k$', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Energy $E(k)$', fontsize=13, fontweight='bold')\n",
    "    ax.set_title(f'Energy Spectrum - Re={analyzer.reynolds:.0f}, RH={analyzer.ride_height:.0f}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3, which='both', linestyle=':')\n",
    "    \n",
    "    if analyzer.kolmogorov_slope:\n",
    "        textstr = f'Slope: {analyzer.kolmogorov_slope:.2f}'\n",
    "        ax.text(0.05, 0.05, textstr, transform=ax.transAxes, fontsize=10,\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f\"rh{analyzer.ride_height:.0f}_re{analyzer.reynolds:.0f}_spectrum.png\"\n",
    "    plt.savefig(results_dir / \"spectra\" / filename, dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\" {filename}\")\n",
    "\n",
    "print(\"\\nEnergy spectra complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz_velpressure",
   "metadata": {},
   "source": [
    "## Velocity + Pressure Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating velocity + pressure visualizations...\\n\")\n",
    "\n",
    "for analyzer in all_analyzers:\n",
    "    if len(analyzer.velocity_snapshots) == 0:\n",
    "        continue\n",
    "    \n",
    "    velocity = analyzer.velocity_snapshots[-1]\n",
    "    pressure = analyzer.pressure_snapshots[-1]\n",
    "    step = analyzer.snapshot_steps[-1]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    # Velocity\n",
    "    ax = axes[0]\n",
    "    im = ax.imshow(velocity, origin='lower', cmap='magma', vmin=0, vmax=0.15, interpolation='bilinear')\n",
    "    ax.set_title(f'Velocity Field | Re={analyzer.reynolds:.0f} | Step {step}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('x (lattice units)', fontsize=11)\n",
    "    ax.set_ylabel('y (lattice units)', fontsize=11)\n",
    "    cbar = plt.colorbar(im, ax=ax, pad=0.02)\n",
    "    cbar.set_label('Velocity Magnitude |u|', fontsize=11)\n",
    "    \n",
    "    # Pressure\n",
    "    ax = axes[1]\n",
    "    vmax_p = np.nanpercentile(np.abs(pressure), 99)\n",
    "    im = ax.imshow(pressure, origin='lower', cmap='RdBu_r', vmin=-vmax_p, vmax=vmax_p, interpolation='bilinear')\n",
    "    ax.set_title(f'Pressure Field | Re={analyzer.reynolds:.0f} | Step {step}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('x (lattice units)', fontsize=11)\n",
    "    ax.set_ylabel('y (lattice units)', fontsize=11)\n",
    "    cbar = plt.colorbar(im, ax=ax, pad=0.02)\n",
    "    cbar.set_label('Pressure Coefficient $C_p$', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f\"rh{analyzer.ride_height:.0f}_re{analyzer.reynolds:.0f}_fields.png\"\n",
    "    plt.savefig(results_dir / \"pressure\" / filename, dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\" {filename}\")\n",
    "\n",
    "print(\"\\nField visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COMPLETE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTotal configurations: {len(all_analyzers)}\")\n",
    "\n",
    "# Attractor types\n",
    "attractor_counts = {}\n",
    "for a in all_analyzers:\n",
    "    atype = a.attractor_type\n",
    "    attractor_counts[atype] = attractor_counts.get(atype, 0) + 1\n",
    "\n",
    "print(f\"\\nDynamical Regimes:\")\n",
    "for atype, count in sorted(attractor_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"   {atype}: {count} ({100*count/len(all_analyzers):.1f}%)\")\n",
    "\n",
    "# Chaos statistics\n",
    "chaotic = [a for a in all_analyzers if a.lyapunov_exponent and a.lyapunov_exponent > 0.01]\n",
    "print(f\"\\n Chaotic regimes: {len(chaotic)}/{len(all_analyzers)} ({100*len(chaotic)/len(all_analyzers):.1f}%)\")\n",
    "\n",
    "if chaotic:\n",
    "    max_lyap = max(a.lyapunov_exponent for a in chaotic)\n",
    "    print(f\"   Maximum λ: {max_lyap:.4f}\")\n",
    "\n",
    "# Vortex shedding\n",
    "shedding = [a for a in all_analyzers if a.vortex_shedding]\n",
    "print(f\"\\n Vortex shedding: {len(shedding)}/{len(all_analyzers)} cases\")\n",
    "\n",
    "# Bifurcations\n",
    "if USE_BIFURCATION_MODE:\n",
    "    bifurcations = []\n",
    "    for i in range(1, len(all_analyzers)):\n",
    "        if all_analyzers[i].attractor_type != all_analyzers[i-1].attractor_type:\n",
    "            bifurcations.append((\n",
    "                all_analyzers[i].reynolds,\n",
    "                f\"{all_analyzers[i-1].attractor_type} → {all_analyzers[i].attractor_type}\"\n",
    "            ))\n",
    "    \n",
    "    print(f\"\\n Bifurcations detected: {len(bifurcations)}\")\n",
    "    for param, transition in bifurcations:\n",
    "        print(f\"   Re={param:.0f}: {transition}\")\n",
    "\n",
    "print(f\"\\n All results saved to: {results_dir}\")\n",
    "print(f\"\\nGenerated outputs:\")\n",
    "print(f\"   {len(list((results_dir / 'spectra').glob('*.png')))} energy spectra\")\n",
    "print(f\"   {len(list((results_dir / 'pressure').glob('*.png')))} flow field visualizations\")\n",
    "print(f\"   {len(list((results_dir / 'chaos').glob('*.json')))} chaos analysis reports\")\n",
    "if USE_BIFURCATION_MODE:\n",
    "    print(f\"    bifurcation diagram\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
